# EvalVerse

![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?logo=TypeScript&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.8+-3776AB?logo=Python&logoColor=white)
![React](https://img.shields.io/badge/React-18.2-61DAFB?logo=React&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?logo=FastAPI&logoColor=white)
![MySQL](https://img.shields.io/badge/MySQL-5.7+-4479A1?logo=MySQL&logoColor=white)
![Redis](https://img.shields.io/badge/Redis-6.0+-DC382D?logo=Redis&logoColor=white)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

> ğŸš€ An AI agent and model evaluation platform built on the AutoGen framework, supporting text evaluation and multimodal evaluation (planned). The platform provides complete evaluation workflow management, experiment comparison analysis, and observability tracking.

<div align="center">
  ğŸŒ <strong>English</strong> | <a href="README.zh.md">ç®€ä½“ä¸­æ–‡</a>
</div>

---

## ğŸŒŸ Project Overview

**EvalVerse** is a comprehensive AI agent and model evaluation platform designed for AI engineers, researchers, and teams. Built on a modern architecture with **FastAPI + React + TypeScript**, it enables efficient evaluation workflow management, real-time experiment tracking, and distributed observability.

ğŸ¯ Core Capabilities:

- **Dataset Management**: Import and version datasets in multiple formats (CSV, JSON, Excel)
- **Evaluator System**: Code-based and prompt-based evaluators with dynamic execution
- **Experiment Management**: Batch evaluation with concurrency control and progress tracking
- **Model Configuration**: Secure API key management and model parameter configuration
- **Observability**: Distributed tracing with OpenTelemetry integration
- **Result Analysis**: Experiment comparison and statistical aggregation

---

## ğŸ›  Tech Stack

| Layer | Technology |
|-------|------------|
| **Frontend** | React 18.2 + TypeScript 5.3 + Vite 5.0 |
| **UI Library** | Ant Design 5.12 |
| **Backend** | FastAPI 0.109 + Python 3.8+ |
| **Database** | MySQL 5.7+ (SQLAlchemy 2.0) |
| **Task Queue** | Celery 5.3 + Redis 5.0 |
| **LLM Framework** | AutoGen 0.2.12 |
| **Observability** | OpenTelemetry 1.22 |

---

## ğŸ§  Typical Use Cases

| Scenario | Description |
|----------|-------------|
| **Model Evaluation** | Evaluate multiple LLM models on custom datasets with various evaluators |
| **Experiment Comparison** | Compare experiment results across different model configurations |
| **Custom Evaluator Development** | Create and test custom evaluation logic using code evaluators |
| **Batch Processing** | Run large-scale evaluations with concurrency control and progress tracking |
| **Observability Analysis** | Trace and analyze evaluation execution paths using OpenTelemetry |
| **Model Performance Tracking** | Track model performance over time with versioned experiments |

---

## ğŸš§ Planned Features

| | Feature | Description |
|---|---|-------------|
| <span style="font-size: 2em">â˜</span> | **Prompt Template Library** | Create reusable prompt templates with variable placeholders |
| <span style="font-size: 2em">â˜</span> | **Prompt Version Control** | Git-like version diff comparison and rollback mechanism |
| <span style="font-size: 2em">â˜</span> | **Prompt A/B Testing** | Multi-version prompt comparison experiments with automated analysis |
| <span style="font-size: 2em">â˜</span> | **Intelligent Data Generation** | Auto-generate test data based on prompt templates, support multiple scenarios (QA, dialogue, summarization, translation) |
| <span style="font-size: 2em">â˜</span> | **Data Annotation Interface** | Human annotation workspace with batch annotation tools and multi-annotator consistency analysis |
| <span style="font-size: 2em">â˜</span> | **Human-in-the-Loop Annotation** | AI pre-annotation + human review with active learning |

---

## ğŸ“ Changelog

### v1.0.0 (Current)

**Initial Release** - Complete evaluation platform with core features:

- âœ… **Dataset Management**: Import and version datasets in CSV, JSON, Excel formats
- âœ… **Evaluator System**: Code-based and prompt-based evaluators with dynamic execution
- âœ… **Experiment Management**: Batch evaluation with concurrency control and progress tracking
- âœ… **Model Configuration**: Secure API key management and model parameter configuration
- âœ… **Model Set Management**: Batch model evaluation with model set configuration
- âœ… **Observability**: Distributed tracing with OpenTelemetry integration
- âœ… **Result Analysis**: Experiment comparison and statistical aggregation
- âœ… **Evaluator Records**: Execution history and detailed evaluation logs

---

## ğŸ“ Project Structure

```
evalverse/
â”œâ”€â”€ backend/                    # Python Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/            # API Routes
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset.py     # Dataset API
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluator.py   # Evaluator API
â”‚   â”‚   â”‚   â”œâ”€â”€ experiment.py  # Experiment API
â”‚   â”‚   â”‚   â”œâ”€â”€ model_config.py # Model Config API
â”‚   â”‚   â”‚   â”œâ”€â”€ model_set.py   # Model Set API
â”‚   â”‚   â”‚   â””â”€â”€ observability.py # Observability API
â”‚   â”‚   â”œâ”€â”€ core/              # Core Configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py      # App Configuration
â”‚   â”‚   â”‚   â””â”€â”€ database.py    # Database Configuration
â”‚   â”‚   â”œâ”€â”€ models/            # Database Models
â”‚   â”‚   â”œâ”€â”€ services/          # Business Logic Services
â”‚   â”‚   â”œâ”€â”€ tasks/             # Celery Tasks
â”‚   â”‚   â””â”€â”€ utils/             # Utility Functions
â”‚   â”œâ”€â”€ alembic/               # Database Migrations
â”‚   â”œâ”€â”€ main.py                # Application Entry Point
â”‚   â””â”€â”€ requirements.txt        # Python Dependencies
â”‚
â”œâ”€â”€ frontend/                   # React Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # React Components
â”‚   â”‚   â”œâ”€â”€ pages/             # Page Components
â”‚   â”‚   â”œâ”€â”€ services/          # API Services
â”‚   â”‚   â”œâ”€â”€ hooks/             # React Hooks
â”‚   â”‚   â””â”€â”€ utils/             # Utility Functions
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â””â”€â”€ README.md                   # Project Documentation
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Node.js 18+
- MySQL 5.7+ or 8.0+
- Redis 6.0+

### 1. Clone the Repository

```bash
git clone https://github.com/super6865/EvalVrese.git
cd EvalVrese
```

### 2. Backend Setup

#### Install Dependencies

```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

#### Configure Environment Variables

Create a `.env` file in the `backend` directory:

```bash
# Database Configuration
DATABASE_URL=mysql+pymysql://user:password@localhost:3306/evaluation_platform

# Redis Configuration
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# LLM Configuration
OPENAI_API_KEY=your-openai-api-key
DEFAULT_LLM_MODEL=gpt-4

# Security Configuration
SECRET_KEY=your-secret-key-change-in-production

# CORS Configuration
CORS_ORIGINS=["http://localhost:5173","http://localhost:3000"]

# OpenTelemetry Configuration
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
```

#### Initialize Database

1. **Create MySQL Database**:

```sql
CREATE DATABASE evaluation_platform CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
```

2. **Initialize Database Schema** (Choose one method):

**Method 1: Using Alembic Migrations (Recommended)**

```bash
cd backend
alembic upgrade head
```

This will create all necessary tables based on Alembic migration files.

**Method 2: Using SQL Schema File**

```bash
cd backend
mysql -u your_username -p evaluation_platform < schema.sql
```

> **Note**: The `schema.sql` file is provided as an alternative to Alembic migrations. It contains the complete database structure and can be imported directly into MySQL.

#### Start Backend Server

```bash
uvicorn main:app --reload --port 8000
```

Backend API documentation:
- **Swagger UI**: http://localhost:8000/api/docs
- **ReDoc**: http://localhost:8000/api/redoc

#### Start Celery Worker (Optional)

```bash
celery -A app.tasks.celery_app worker --loglevel=info
```

### 3. Frontend Setup

#### Install Dependencies

```bash
cd frontend
npm install
```

#### Configure API URL

Edit `frontend/src/services/api.ts` to ensure the API base URL points to the backend service.

#### Start Development Server

```bash
npm run dev
```

Frontend application: http://localhost:5173

---

## ğŸ“š API Documentation

After starting the backend service, access the API documentation:

- **Swagger UI**: http://localhost:8000/api/docs
- **ReDoc**: http://localhost:8000/api/redoc

---

## ğŸ“– User Guide

For detailed usage instructions and step-by-step tutorials, please refer to:

- **English**: [User Guide](docs/USAGE.md)
- **ä¸­æ–‡**: [ä½¿ç”¨æŒ‡å—](docs/USAGE_zh.md)

The user guide covers:
- Dataset management and data import
- Creating and managing evaluators
- Running experiments and viewing results
- Model configuration and model sets
- Observability and trace analysis
- Best practices and troubleshooting

---

## ğŸ’» Development

### Backend Development

```bash
cd backend
source venv/bin/activate
uvicorn main:app --reload --port 8000
pytest  # Run tests
```

### Frontend Development

```bash
cd frontend
npm run dev
npm run build  # Build for production
npm run lint   # Lint code
```

### Code Style

- **Python**: Follow PEP 8 style guide
- **TypeScript/React**: Use ESLint configuration

---

## ğŸ”§ Troubleshooting

### Common Issues

#### Database Connection Failed
**Problem**: Cannot connect to MySQL database  
**Solution**:
- Check if MySQL service is running
- Verify database connection parameters in `.env`
- Check firewall settings
- Verify database user permissions

#### Redis Connection Failed
**Problem**: Cannot connect to Redis  
**Solution**:
- Ensure Redis service is running: `redis-server`
- Verify `REDIS_URL` in `.env`
- Check Redis port (default: 6379)

#### Celery Worker Not Starting
**Problem**: Celery worker fails to start  
**Solution**:
- Verify Redis connection
- Check Celery broker and backend URLs
- Ensure all dependencies are installed

#### Frontend API Errors
**Problem**: Frontend cannot connect to backend  
**Solution**:
- Verify backend is running on port 8000
- Check CORS configuration in backend
- Verify API base URL in `frontend/src/services/api.ts`

---

## ğŸ¤ Contributing

We welcome all forms of contributions!

### Contribution Process

1. Fork this repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Reporting Issues

If you find bugs or have feature suggestions, please submit them in [GitHub Issues](https://github.com/super6865/EvalVrese/issues).

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ™ Acknowledgments

- [AutoGen](https://github.com/microsoft/autogen) - Microsoft's AutoGen framework
- [Coze Loop](https://github.com/coze-dev/cozeloop) - AI Agent development and operations platform
- [FastAPI](https://fastapi.tiangolo.com/) - Modern, fast web framework
- [React](https://react.dev/) - UI library
- [Ant Design](https://ant.design/) - Enterprise-class UI component library

---

## ğŸŒŸ Support the Project

If you find EvalVerse helpful, please give it a â­ **Star**!  
Your support motivates us to keep improving and maintaining the project ğŸ’™

> GitHub: [https://github.com/super6865/EvalVrese](https://github.com/super6865/EvalVrese)

---

## ğŸ“ Contact

For questions or suggestions, please contact us through:

- GitHub Issues: [Submit an Issue](https://github.com/super6865/EvalVrese/issues)
- Email: 15979193012@163.com

---

**Happy Evaluating! ğŸ‰**
